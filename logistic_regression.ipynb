{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     left_top  left_mid  left_bot  right_top  right_mid  right_bot\n",
      "0    1.084829  1.337654  1.137629   1.203465   1.443387   1.367903\n",
      "2    1.220854  1.456986  1.105298   1.292796   1.554915   1.303239\n",
      "8    1.081962  1.055988  0.411925   1.275803   1.166661   0.523606\n",
      "9    0.808323  0.902035  0.525554   0.680819   1.124125   0.472381\n",
      "10   0.787006  0.778107  0.776500   0.801138   0.869505   1.014244\n",
      "..        ...       ...       ...        ...        ...        ...\n",
      "266  1.474750  1.351573  1.126588   1.320049   1.353936   1.041082\n",
      "270  1.188919  1.292762  1.240975   1.521868   1.540497   1.467022\n",
      "274  1.142510  1.118758  1.142293   1.329997   1.353078   1.283374\n",
      "278  0.894736  0.921019  0.988501   1.083722   1.137952   1.036259\n",
      "282  0.943719  0.900177  0.939900   1.076516   1.123459   1.036797\n",
      "\n",
      "[91 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#pandas returns a pandas dataframe. MAKE SURE YOU RUN THIS CELL \n",
    "labeled_full_scan3 = pd.read_excel('labeled_full_scan3.xlsx')\n",
    "labeled_full_scan3 = labeled_full_scan3.drop_duplicates(subset = \"subject\")\n",
    "label = labeled_full_scan3['label']=='NSIP'\n",
    "subjects = labeled_full_scan3['subject']\n",
    "labeled_full_scan3 = labeled_full_scan3.drop(columns = ['subject','subject_num','label'])\n",
    "values = labeled_full_scan3.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "values_scaled = min_max_scaler.fit_transform(values)\n",
    "df = pd.DataFrame(values_scaled)\n",
    "\n",
    "# organizes data for splitting and training\n",
    "y = label.values\n",
    "x = df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits data into test and train\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x,y, test_size = .2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      0.60      0.57        10\n",
      "        True       0.50      0.44      0.47         9\n",
      "\n",
      "    accuracy                           0.53        19\n",
      "   macro avg       0.52      0.52      0.52        19\n",
      "weighted avg       0.52      0.53      0.52        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#performs the logistic regression for the data above\n",
    "model = LogisticRegression(solver='liblinear', random_state=0, class_weight = 'balanced')\n",
    "model.fit(xTrain,yTrain)\n",
    "\n",
    "#evaluate the model\n",
    "yTestPredict = model.predict(xTest)\n",
    "confusion_matrix(yTest,yTestPredict)\n",
    "\n",
    "#print calssification report\n",
    "print(classification_report(yTest,yTestPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003023_hrep\n"
     ]
    }
   ],
   "source": [
    "#process the data 'NotAll_scan_2outin_all_type.xls'\n",
    "labeled_full_scan3 = pd.read_excel('labeled_full_scan3.xlsx')\n",
    "labeled_full_scan3 = labeled_full_scan3.drop_duplicates(subset = \"subject\")\n",
    "\n",
    "df_raw = pd.read_excel('NotAll_scan_2outin_all_type.xls', header = None)\n",
    "df = pd.DataFrame()\n",
    "print(subjects.values[1])\n",
    "for i in range(len(subjects.values)):\n",
    "    d = pd.DataFrame(df_raw[df_raw[0].str.match(subjects.values[i])])\n",
    "    df = df.append(d)\n",
    "\n",
    "df = df.drop_duplicates(subset = 0)\n",
    "df = df.drop(columns = [0])\n",
    "values = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "values_scaled = min_max_scaler.fit_transform(values)\n",
    "df = pd.DataFrame(values_scaled)\n",
    "\n",
    "df_2 = pd.DataFrame(subjects.values)\n",
    "df_3 = pd.DataFrame(labeled_full_scan3['label'].values)\n",
    "df = pd.concat([df_2,df,df_3],axis = 1)\n",
    "df\n",
    "#export the csv\n",
    "df.to_csv('features_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003023_hrep\n"
     ]
    }
   ],
   "source": [
    "#process the data 'NotAll_scan_2outin_all_type.xls'\n",
    "labeled_full_scan3 = pd.read_excel('labeled_full_scan3.xlsx')\n",
    "labeled_full_scan3 = labeled_full_scan3.drop_duplicates(subset = \"subject\")\n",
    "\n",
    "df_raw = pd.read_excel('NotAll_scan_3split_all_type.xls', header = None)\n",
    "df = pd.DataFrame()\n",
    "print(subjects.values[1])\n",
    "for i in range(len(subjects.values)):\n",
    "    d = pd.DataFrame(df_raw[df_raw[0].str.match(subjects.values[i])])\n",
    "    df = df.append(d)\n",
    "\n",
    "df = df.drop_duplicates(subset = 0)\n",
    "df = df.drop(columns = [0])\n",
    "values = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "values_scaled = min_max_scaler.fit_transform(values)\n",
    "df = pd.DataFrame(values_scaled)\n",
    "\n",
    "df_2 = pd.DataFrame(subjects.values)\n",
    "df_3 = pd.DataFrame(labeled_full_scan3['label'].values)\n",
    "df = pd.concat([df_2,df,df_3],axis = 1)\n",
    "\n",
    "#export the  csv \n",
    "df.to_csv('features_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "003023_hrep\n",
      "                0         0         1         2         3         4   \\\n",
      "0    003023_highBW  0.674474  0.681490  0.655149  0.765014  0.630169   \n",
      "1      003023_hrep  0.837056  0.811875  0.778164  0.880141  0.689728   \n",
      "2    002112_highBW  0.293006  0.497527  0.250623  0.504043  0.235331   \n",
      "3    002113_highBW  0.405261  0.557468  0.287806  0.293864  0.036179   \n",
      "4    002114_highBW  0.284322  0.263104  0.375829  0.321515  0.331031   \n",
      "..             ...       ...       ...       ...       ...       ...   \n",
      "86    003024A_hrep  0.981538  0.970831  0.827877  0.849198  0.611615   \n",
      "87   003025_highBW  0.656072  0.804832  0.700656  0.817999  0.496031   \n",
      "88     003025_hrep  0.639520  0.628149  0.609859  0.670757  0.480406   \n",
      "89  003025A_highBW  0.486690  0.434038  0.513440  0.488874  0.350229   \n",
      "90    003025A_hrep  0.475015  0.425379  0.502064  0.474962  0.369257   \n",
      "\n",
      "          5         6         7         8   ...        63        64        65  \\\n",
      "0   0.643494  0.806837  0.724079  0.717011  ...  0.555913  0.742040  0.615021   \n",
      "1   0.683868  0.856811  0.828484  0.665005  ...  0.406247  0.622717  0.484283   \n",
      "2   0.442976  0.554492  0.576950  0.492806  ...  0.000000  0.000000  0.000000   \n",
      "3   0.143351  0.420543  0.489037  0.283479  ...  0.079922  0.105507  0.052488   \n",
      "4   0.270444  0.392119  0.351509  0.374729  ...  0.828083  0.832589  0.835587   \n",
      "..       ...       ...       ...       ...  ...       ...       ...       ...   \n",
      "86  0.600934  0.818694  0.765484  0.593221  ...  0.560361  0.320525  0.597944   \n",
      "87  0.623350  0.954872  0.928522  0.812606  ...  0.330035  0.354281  0.385522   \n",
      "88  0.513278  0.781594  0.742193  0.684316  ...  0.471274  0.567075  0.444003   \n",
      "89  0.377683  0.624507  0.562806  0.499218  ...  0.510501  0.684392  0.637663   \n",
      "90  0.354977  0.565103  0.505576  0.548591  ...  0.513595  0.706160  0.681133   \n",
      "\n",
      "          66        67        68        69        70        71    0   \n",
      "0   0.623090  0.550000  0.625497  0.510648  0.795555  0.821247   IPF  \n",
      "1   0.498079  0.488560  0.447251  0.382940  0.733193  0.763145   IPF  \n",
      "2   0.198704  0.210888  0.182584  0.215664  0.291560  0.417929  NSIP  \n",
      "3   0.000000  0.000000  0.000000  0.067272  0.183228  0.225835  NSIP  \n",
      "4   0.747166  0.780493  0.876441  0.881892  0.777281  0.818844  NSIP  \n",
      "..       ...       ...       ...       ...       ...       ...   ...  \n",
      "86  0.572136  0.629481  0.456006  0.653310  0.646675  0.767514   IPF  \n",
      "87  0.592626  0.687143  0.511594  0.509896  0.596943  0.614149   IPF  \n",
      "88  0.721626  0.792804  0.655486  0.600544  0.660448  0.638798   IPF  \n",
      "89  0.701745  0.758988  0.552758  0.647371  0.727712  0.773306   IPF  \n",
      "90  0.793841  0.659064  0.690277  0.630941  0.786522  0.779547   IPF  \n",
      "\n",
      "[91 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "#process the data NotAll_scan_2outin_3cut_all_type.xls\n",
    "labeled_full_scan3 = pd.read_excel('labeled_full_scan3.xlsx')\n",
    "labeled_full_scan3 = labeled_full_scan3.drop_duplicates(subset = \"subject\")\n",
    "\n",
    "df_raw = pd.read_excel('NotAll_scan_2outin_3cut_all_type.xls', header = None,keep_default_nan = False)\n",
    "df = pd.DataFrame()\n",
    "print(subjects.values[1])\n",
    "for i in range(len(subjects.values)):\n",
    "    d = pd.DataFrame(df_raw[df_raw[0].str.match(subjects.values[i])])\n",
    "    df = df.append(d)\n",
    "\n",
    "df = df.drop_duplicates(subset = 0)\n",
    "df = df.drop(columns = [0])\n",
    "values = df.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "values_scaled = min_max_scaler.fit_transform(values)\n",
    "df = pd.DataFrame(values_scaled)\n",
    "\n",
    "df_2 = pd.DataFrame(subjects.values)\n",
    "df_3 = pd.DataFrame(labeled_full_scan3['label'].values)\n",
    "df = pd.concat([df_2,df,df_3],axis = 1)\n",
    "print(df)\n",
    "#export to csv \n",
    "\n",
    "df.to_csv('features_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
